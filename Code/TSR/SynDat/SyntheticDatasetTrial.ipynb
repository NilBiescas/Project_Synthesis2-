{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating_DS3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"lQyI255cY94lD6HTwQr7\")\n",
    "project = rf.workspace(\"tabledataset\").project(\"table-dataset-9qyaq\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def add_bkg_noise(img):\n",
    "    orig = img.copy()\n",
    "    bkg = np.zeros_like(img)\n",
    "    \n",
    "    # choose a random num between 3 and 25\n",
    "    num_letters = random.randint(5, 25)\n",
    "    \n",
    "    #choose a random combination of letters and numbers with the length of num_letters\n",
    "    letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789              '\n",
    "    bkg_text = ''.join(random.choices(letters, k=num_letters))\n",
    "    \n",
    "    alpha = random.randint(0, 50)\n",
    "    font_size = random.randint(15, 30)\n",
    "    \n",
    "    img = Image.fromarray(img)\n",
    "    \n",
    "    bkg_text = bkg_text * (img.size[0] * 5 // (len(bkg_text)*font_size) + 1)\n",
    "\n",
    "    # create a new image with the bkg_text\n",
    "    bkg_img = Image.new('RGB', img.size, (0, 0, 0))\n",
    "    for j in range(0, img.size[1], int(font_size*1.1)):\n",
    "        i = random.randint(-200, 0)\n",
    "        draw = ImageDraw.Draw(bkg_img)\n",
    "        draw.text((i, j), bkg_text, fill=(alpha, alpha, alpha), font_size=font_size)\n",
    "    \n",
    "    solid_color = Image.new('RGB', img.size, (0, 0, 0))\n",
    "    bkg_img = bkg_img.convert('L')\n",
    "    solid_color.putalpha(bkg_img)\n",
    "    img.paste(solid_color, (0, 0), solid_color)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas: \n",
    "- Maximize and minimize tables (padding?)\n",
    "    - Take from the annotations what are the dimensions of the table\n",
    "    - Remove or add the parts affected (add padding after reducing the size of the table, delete the surrounding area before maximizing.)\n",
    "    - Apply on said pixels and apply said actions to both the annotations and the image?\n",
    "- Move the table (Padding?)\n",
    "    - Should be within the limits of the image\n",
    "    - Cover the original space in background color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def maximize():\n",
    "    return\n",
    "def minimize():\n",
    "    return\n",
    "def move(): \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def add_transparent_image(background, foreground, x_offset=None, y_offset=None):\n",
    "    bg_h, bg_w, bg_channels = background.shape\n",
    "    fg_h, fg_w, fg_channels = foreground.shape\n",
    "\n",
    "    assert bg_channels == 3, f'background image should have exactly 3 channels (RGB). found:{bg_channels}'\n",
    "    assert fg_channels == 4, f'foreground image should have exactly 4 channels (RGBA). found:{fg_channels}'\n",
    "\n",
    "    # center by default\n",
    "    if x_offset is None: x_offset = (bg_w - fg_w) // 2\n",
    "    if y_offset is None: y_offset = (bg_h - fg_h) // 2\n",
    "\n",
    "    w = min(fg_w, bg_w, fg_w + x_offset, bg_w - x_offset)\n",
    "    h = min(fg_h, bg_h, fg_h + y_offset, bg_h - y_offset)\n",
    "\n",
    "    if w < 1 or h < 1: return\n",
    "\n",
    "    # clip foreground and background images to the overlapping regions\n",
    "    bg_x = max(0, x_offset)\n",
    "    bg_y = max(0, y_offset)\n",
    "    fg_x = max(0, x_offset * -1)\n",
    "    fg_y = max(0, y_offset * -1)\n",
    "    foreground = foreground[fg_y:fg_y + h, fg_x:fg_x + w]\n",
    "    background_subsection = background[bg_y:bg_y + h, bg_x:bg_x + w]\n",
    "\n",
    "    # separate alpha and color channels from the foreground image\n",
    "    foreground_colors = foreground[:, :, :3]\n",
    "    alpha_channel = foreground[:, :, 3] / 255  # 0-255 => 0.0-1.0\n",
    "\n",
    "    # construct an alpha_mask that matches the image shape\n",
    "    alpha_mask = np.dstack((alpha_channel, alpha_channel, alpha_channel))\n",
    "\n",
    "    # combine the background with the overlay image weighted by alpha\n",
    "    composite = background_subsection * (1 - alpha_mask) + foreground_colors * alpha_mask\n",
    "\n",
    "    # overwrite the section of the background image that has been updated\n",
    "    background[bg_y:bg_y + h, bg_x:bg_x + w] = composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_annotations_from_image(dataset, image_id):\n",
    "    a = [a for a in dataset[\"annotations\"] if a[\"image_id\"] == image_id]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def on_top_of_text(bb, annotations): \n",
    "    # bb = [x, y, w, h]\n",
    "    # it any of the corners of the bb is inside any of the annotations, return True\n",
    "    x, y, w, h = bb\n",
    "    for a in annotations:\n",
    "        print(\"test\", a[\"bbox\"])\n",
    "        x2, y2, w2, h2 = a[\"bbox\"]\n",
    "        if x2 <= x <= x2+w2 and y2 <= y <= y2+h2: return True\n",
    "        if x2 <= x+w <= x2+w2 and y2 <= y <= y2+h2: return True\n",
    "        if x2 <= x <= x2+w2 and y2 <= y+h <= y2+h2: return True\n",
    "        if x2 <= x+w <= x2+w2 and y2 <= y+h <= y2+h2: return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_COCO_annotation(dataset, image_id, category_id, x, y, w, h):\n",
    "    # print(dataset)\n",
    "    annotation = {\n",
    "        \"area\": w * h,\n",
    "        \"iscrowd\": 0,\n",
    "        \"image_id\": image_id,\n",
    "        \"bbox\": [x, y, w, h],\n",
    "        \"category_id\": category_id, \n",
    "        \"id\": len(dataset[\"annotations\"]) + 3265447 + 14423 + 1,\n",
    "    }\n",
    "    \n",
    "    dataset[\"annotations\"].append(annotation)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def add_stamps(n, page, stamps, stamps_ds, dataset, image_id, split=\"train\"):\n",
    "    label = 7\n",
    "    \n",
    "    img = page.copy()\n",
    "    \n",
    "    j = 0\n",
    "    while j < n:\n",
    "        idx = np.random.randint(0, len(stamps))\n",
    "        if stamps[idx]['split'] != split:\n",
    "            continue\n",
    "        try: \n",
    "            stamp = cv2.imread(f\"{stamps_ds}/preprocessed/{stamps[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "            stamp = cv2.cvtColor(stamp, cv2.COLOR_BGR2RGBA)\n",
    "            \n",
    "            size = np.random.normal(200, 200)\n",
    "            size = int(np.clip(size, 50, page.shape[1]*0.8))\n",
    "            size = int(np.clip(size, 50, page.shape[0]*0.8))\n",
    "            stamp = cv2.resize(stamp, (0,0), fx=size/stamp.shape[1], fy=size/stamp.shape[0])\n",
    "            \n",
    "            angle = np.random.randint(-30, 30)\n",
    "            center = (stamp.shape[1]//2, stamp.shape[0]//2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "            stamp = cv2.warpAffine(stamp, M, (stamp.shape[1], stamp.shape[0]))\n",
    "            \n",
    "            # print(f\"stamp: {stamp.shape}, page: {page.shape}\", page.shape[1]-stamp.shape[1], page.shape[0]-stamp.shape[0])\n",
    "            \n",
    "            # choose x_offset and y_offset while the stamp is on top of any annotation\n",
    "            x_offset = np.random.randint(0, page.shape[1] - stamp.shape[1])\n",
    "            y_offset = np.random.randint(0, page.shape[0] - stamp.shape[0])\n",
    "\n",
    "            alpha = np.random.normal(1-(1/(page.shape[1]/size)), 0.2)\n",
    "            # print(f\"alpha: {0.8-(1/(page.shape[1]/size))}\")\n",
    "            alpha = np.clip(alpha, 0.1, 1)\n",
    "            \n",
    "            add_transparent_image(img, stamp*alpha, x_offset, y_offset)\n",
    "            # cv2.rectangle(img, (x_offset, y_offset), (x_offset+stamp.shape[1], y_offset+stamp.shape[0]), (0, 255, 0), 4)\n",
    "            \n",
    "            dataset = create_COCO_annotation(dataset, image_id, label, x_offset, y_offset, stamp.shape[1], stamp.shape[0])\n",
    "        \n",
    "            j += 1\n",
    "        except:\n",
    "            print(f\"Error adding stamp {stamps[idx]['file_name']}\")\n",
    "            raise(Exception)\n",
    "        \n",
    "    return img, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def add_qrs(n, page, qrs, qrs_dataset, dataset, image_id, split='train'):\n",
    "    label = 8\n",
    "    img = page.copy()\n",
    "        \n",
    "    j = 0\n",
    "    while j < n:\n",
    "        idx = np.random.randint(0, len(qrs))\n",
    "        if qrs[idx]['split'] != split:\n",
    "            continue\n",
    "        try: \n",
    "            \n",
    "            # print(f\"Adding QR code {qrs_dataset}/preprocessed/{qrs[idx]['file_name']}\")\n",
    "            \n",
    "            qr = cv2.imread(f\"{qrs_dataset}/preprocessed/{qrs[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "            # crop a 5 % of the image per each side\n",
    "            qr = qr[qr.shape[0]//10:qr.shape[0]-(qr.shape[0]//10), qr.shape[1]//10:qr.shape[1]-(qr.shape[1]//10)]\n",
    "\n",
    "\n",
    "            size = np.random.randint(50, 175)\n",
    "            qr = cv2.resize(qr, (0,0), fx=size/qr.shape[1], fy=size/qr.shape[0])\n",
    "            \n",
    "            x_offset = np.random.randint(0, page.shape[1] - qr.shape[1])\n",
    "            y_offset = np.random.randint(0, page.shape[0] - qr.shape[0])\n",
    "\n",
    "            alpha = np.random.normal(0.9, 0.2)\n",
    "            alpha = np.clip(alpha, 0.1, 0.85)\n",
    "            \n",
    "            add_transparent_image(img, qr*alpha, x_offset, y_offset)\n",
    "            #cv2.rectangle(img, (x_offset, y_offset), (x_offset+qr.shape[1], y_offset+qr.shape[0]), (0, 0, 255), 3)\n",
    "            \n",
    "            dataset = create_COCO_annotation(dataset, image_id, label, x_offset, y_offset, qr.shape[1], qr.shape[0])\n",
    "        \n",
    "            j += 1\n",
    "        except:\n",
    "            print(f\"Error adding qr {qrs[idx]['file_name']}\")\n",
    "            raise(Exception)\n",
    "            \n",
    "    return img, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def add_barcodes(n, page, barcodes, barcodes_dataset, dataset, image_id, split='train'):\n",
    "    label = 9\n",
    "    img = page.copy()\n",
    "        \n",
    "    j = 0\n",
    "    while j < n:\n",
    "        idx = np.random.randint(0, len(barcodes))\n",
    "        if barcodes[idx]['split'] != split:\n",
    "            continue\n",
    "        try: \n",
    "            \n",
    "            # print(f\"Adding QR code {qrs_dataset}/preprocessed/{qrs[j]['file_name']}\")\n",
    "            \n",
    "            barcode = cv2.imread(f\"{barcodes_dataset}/preprocessed/{barcodes[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "            # crop a 5 % of the image per each side\n",
    "            # barcode = barcode[qr.shape[0]//10:qr.shape[0]-(qr.shape[0]//10), qr.shape[1]//10:barcode.shape[1]-(barcode.shape[1]//10)]\n",
    "\n",
    "\n",
    "            size = np.random.randint(50, 175)\n",
    "            barcode = cv2.resize(barcode, (0,0), fx=size/barcode.shape[1], fy=size/barcode.shape[0])\n",
    "            \n",
    "            x_offset = np.random.randint(0, page.shape[1] - barcode.shape[1])\n",
    "            y_offset = np.random.randint(0, page.shape[0] - barcode.shape[0])\n",
    "\n",
    "            alpha = np.random.normal(0.9, 0.2)\n",
    "            alpha = np.clip(alpha, 0.1, 1)\n",
    "            \n",
    "            add_transparent_image(img, barcode*alpha, x_offset, y_offset)\n",
    "            # cv2.rectangle(img, (x_offset, y_offset), (x_offset+barcode.shape[1], y_offset+barcode.shape[0]), (0, 255, 255), 3)\n",
    "            \n",
    "            dataset = create_COCO_annotation(dataset, image_id, label, x_offset, y_offset, barcode.shape[1], barcode.shape[0])\n",
    "            \n",
    "            j += 1\n",
    "        except:\n",
    "            print(f\"Error adding barcode {barcodes[idx]['file_name']}\")\n",
    "            raise(Exception)\n",
    "            \n",
    "    return img, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def add_border(dir_borders, img):\n",
    "    try:\n",
    "        img = Image.fromarray(img)\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "    border = random.choice(os.listdir(dir_borders))\n",
    "    border = Image.open(f\"{dir_borders}/{border}\")\n",
    "    print(border.size, img.size)\n",
    "    border = border.resize(img.size)\n",
    "    img.paste(border, (0, 0), border)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_gradient_mask(shape, direction='vertical', direction_type='dark_to_light'):\n",
    "    height, width = shape\n",
    "    gradient_mask = np.zeros(shape, dtype=np.float32)\n",
    "    \n",
    "    maxx = random.uniform(1.1, 1.5)\n",
    "    minn = random.uniform(0.5, 0.8)\n",
    "    \n",
    "    if direction == 'vertical':\n",
    "        for y in range(height):\n",
    "            alpha = y / height if direction_type == 'dark_to_light' else 1 - y / height\n",
    "            alpha = alpha * (maxx - minn) + minn\n",
    "            gradient_mask[y, :] = alpha\n",
    "    elif direction == 'horizontal':\n",
    "        for x in range(width):\n",
    "            alpha = x / width if direction_type == 'dark_to_light' else 1 - x / width\n",
    "            alpha = alpha * (maxx - minn) + minn\n",
    "            gradient_mask[:, x] = alpha\n",
    "    elif direction == 'diagonal':\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                alpha = min(y, x) / max(height, width) if direction_type == 'dark_to_light' else 1 - min(y, x) / max(height, width)\n",
    "                alpha = alpha * (maxx - minn) + minn\n",
    "                gradient_mask[y, x] = alpha\n",
    "    else:\n",
    "        gradient_mask = np.ones(shape, dtype=np.uint8)\n",
    "    return gradient_mask\n",
    "\n",
    "def add_lighting_and_yellow_tint(img):\n",
    "    img_array = np.array(img)\n",
    "    # Randomly adjust the yellowish tint\n",
    "    yellow_factor = random.uniform(0.6, 1)  # Random factor between 0.5 and 1.0\n",
    "    \n",
    "    corr_green = random.uniform(0.7, 1)\n",
    "    corr_red = random.uniform(1, 1.2)\n",
    "    \n",
    "    yellow_factor_red = np.clip(yellow_factor*corr_red, 0, 1)\n",
    "    \n",
    "    \n",
    "    img_array[:, :, 0] = img_array[:, :, 0] * yellow_factor_red  # Increasing red channel\n",
    "    img_array[:, :, 1] = img_array[:, :, 1] * yellow_factor  # Reducing green channel\n",
    "    img_array[:, :, 2] = img_array[:, :, 2] * yellow_factor * corr_green  # Reducing blue channel\n",
    "\n",
    "    # Convert array back to image\n",
    "    yellow_tint_img = Image.fromarray(img_array)\n",
    "\n",
    "    # Generate a random direction for the lighting overlay\n",
    "    directions = ['vertical', 'horizontal', 'diagonal', 'none']\n",
    "    direction = random.choice(directions)\n",
    "    \n",
    "    # Generate a random direction type (dark_to_light or light_to_dark) if the direction is horizontal or vertical\n",
    "    direction_type = 'dark_to_light' if random.choice([True, False]) else 'light_to_dark'\n",
    "\n",
    "    # Generate gradient mask with random direction and type\n",
    "    gradient_mask = generate_gradient_mask(img_array.shape[:2], direction, direction_type)\n",
    "    lighting_factor = random.uniform(0.2, 0.5)  # Random factor between 0.2 and 0.5\n",
    "    img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)\n",
    "    \n",
    "    # transform the uint8 image to float32\n",
    "    img_array = img_array.astype(np.float32)\n",
    "    img_array[:, :, 0] = img_array[:, :, 0] * gradient_mask\n",
    "    img_array[:, :, 0] = np.clip(img_array[:, :, 0], 0, 254)\n",
    "    print(img_array[:, :, 0].shape, img_array[:, :, 0].min(), img_array[:, :, 0].max())\n",
    "    \n",
    "    # transform the float32 image to uint8\n",
    "    img_array = img_array.astype(np.uint8)\n",
    "    \n",
    "    # Convert lab to rgb\n",
    "    img_array = cv2.cvtColor(img_array, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "    # Convert array back to image\n",
    "    overlayed_img = Image.fromarray(img_array)\n",
    "\n",
    "    return overlayed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def add_signatures(n, list_of_imgs, signatures, signatures_ds, dataset, image_id, split='train'):\n",
    "    label = 6\n",
    "    \n",
    "    j = 0\n",
    "    while j < n:\n",
    "        idx = np.random.randint(0, len(signatures))\n",
    "        if signatures[idx]['split'] != split:\n",
    "            continue\n",
    "        try: \n",
    "            #signature = cv2.imread(f\"{signatures_ds}/dataset3/forge_preprocessed/{signatures[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "            signature = cv2.imread(f\"{signatures_ds}/preprocessed/{signatures[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "            signature = cv2.cvtColor(signature, cv2.COLOR_BGR2RGBA)\n",
    "            #print(signature)\n",
    "            \n",
    "            size = np.random.randint(50, 200)\n",
    "            signature = cv2.resize(signature, (0,0), fx=size/signature.shape[1], fy=size/signature.shape[0])\n",
    "            \n",
    "            # rotate the image randomly\n",
    "            angle = np.random.randint(-30, 30)\n",
    "            center = (signature.shape[1]//2, signature.shape[0]//2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "            signature = cv2.warpAffine(signature, M, (signature.shape[1], signature.shape[0]))\n",
    "            \n",
    "            \n",
    "            x_offset = np.random.randint(0, list_of_imgs[0].shape[1] - signature.shape[1])\n",
    "            y_offset = np.random.randint(0, list_of_imgs[0].shape[0] - signature.shape[0])\n",
    "\n",
    "            alpha = np.random.normal(0.9, 0.2)\n",
    "            alpha = 1\n",
    "            \n",
    "            for img in list_of_imgs:\n",
    "                add_transparent_image(img, signature*alpha, x_offset, y_offset)\n",
    "            # cv2.rectangle(img, (x_offset, y_offset), (x_offset+signature.shape[1], y_offset+signature.shape[0]), (255, 0, 255), 3)\n",
    "            \n",
    "            dataset = create_COCO_annotation(dataset, image_id, label, x_offset, y_offset, signature.shape[1], signature.shape[0])\n",
    "            \n",
    "            j += 1\n",
    "            \n",
    "        except:\n",
    "            print(f\"Error adding signature {signatures[idx]['file_name']}\")\n",
    "            raise(Exception)\n",
    "            \n",
    "    return list_of_imgs, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "split = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dir2publaynet = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Publaynet\"\n",
    "\n",
    "dir2signatures = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Signatures_dataset\"\n",
    "dataset = \"preprocessed\"\n",
    "\n",
    "dir2stamps = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Stamps_dataset\"\n",
    "dir2qrs = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/QRs_dataset/\"\n",
    "dir2barcodes = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Barcodes_dataset\"\n",
    "dir_borders = r\"C:\\Users\\Maria\\OneDrive - UAB\\Documentos\\3r de IA\\Synthesis project II\\Github\\Project_Synthesis2-\\Datasets\\Borders\"\n",
    "\n",
    "\n",
    "\n",
    "dir2publaynet = \"/hhome/ps2g07/document_analysis/github/Project_Synthesis2-/Datasets/Publaynet\"\n",
    "\n",
    "dir2signatures = \"/hhome/ps2g07/document_analysis/github/Project_Synthesis2-/Datasets/Signatures_dataset\"\n",
    "dataset = \"preprocessed\"\n",
    "\n",
    "dir2stamps = \"/hhome/ps2g07/document_analysis/github/Project_Synthesis2-/Datasets/Stamps_dataset\"\n",
    "dir2qrs = \"/hhome/ps2g07/document_analysis/github/Project_Synthesis2-/Datasets/QRs_dataset/\"\n",
    "dir2barcodes = \"/hhome/ps2g07/document_analysis/github/Project_Synthesis2-/Datasets/Barcodes_dataset\"\n",
    "dir_borders = \"/hhome/ps2g07/document_analysis/github/Project_Synthesis2-/Datasets/Borders\"\n",
    "\n",
    "\n",
    "\n",
    "with open(f\"{dir2publaynet}/{split}_syn.json\", 'r') as f:\n",
    "   publaynet = json.load(f)   \n",
    "\n",
    "\"\"\"with open(f\"{dir2publaynet}/{split}.json\", 'r') as f:\n",
    "     publaynet = json.load(f)\"\"\"\n",
    "\n",
    "with open(f\"{dir2stamps}/splits.json\", 'r') as f:\n",
    "    stamps = json.load(f)\n",
    "    \n",
    "with open(f\"{dir2signatures}/splits.json\", 'r') as f:\n",
    "    signatures = json.load(f) \n",
    "\n",
    "with open(f\"{dir2qrs}/splits.json\", 'r') as f:\n",
    "    qrs = json.load(f)\n",
    "\n",
    "with open(f\"{dir2barcodes}/splits.json\", 'r') as f:\n",
    "    barcodes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dir2publaynet = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Publaynet\"\n",
    "\n",
    "dir2signatures = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Signatures_dataset\"\n",
    "dataset = \"preprocessed\"\n",
    "\n",
    "dir2stamps = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Stamps_dataset\"\n",
    "dir2qrs = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/QRs_dataset/\"\n",
    "dir2barcodes = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Barcodes_dataset\"\n",
    "dir_borders = r\"C:\\Users\\Maria\\OneDrive - UAB\\Documentos\\3r de IA\\Synthesis project II\\Github\\Project_Synthesis2-\\Datasets\\Borders\"\n",
    "\n",
    "\n",
    "\n",
    "dir2publaynet = \"/hhome/ps2g07/document_analysis/github/Project_Synthesis2-/Datasets/Publaynet\"\n",
    "\n",
    "dir2signatures = \"/hhome/ps2g07/document_analysis/github/Project_Synthesis2-/Datasets/Signatures_dataset\"\n",
    "dataset = \"preprocessed\"\n",
    "\n",
    "dir2stamps = \"/hhome/ps2g07/document_analysis/github/Project_Synthesis2-/Datasets/Stamps_dataset\"\n",
    "dir2qrs = \"/hhome/ps2g07/document_analysis/github/Project_Synthesis2-/Datasets/QRs_dataset/\"\n",
    "dir2barcodes = \"/hhome/ps2g07/document_analysis/github/Project_Synthesis2-/Datasets/Barcodes_dataset\"\n",
    "dir_borders = \"/hhome/ps2g07/document_analysis/github/Project_Synthesis2-/Datasets/Borders\"\n",
    "\n",
    "\n",
    "\n",
    "with open(f\"{dir2publaynet}/{split}_syn.json\", 'r') as f:\n",
    "   publaynet = json.load(f)   \n",
    "\n",
    "\"\"\"with open(f\"{dir2publaynet}/{split}.json\", 'r') as f:\n",
    "     publaynet = json.load(f)\"\"\"\n",
    "\n",
    "with open(f\"{dir2stamps}/splits.json\", 'r') as f:\n",
    "    stamps = json.load(f)\n",
    "    \n",
    "with open(f\"{dir2signatures}/splits.json\", 'r') as f:\n",
    "    signatures = json.load(f) \n",
    "\n",
    "with open(f\"{dir2qrs}/splits.json\", 'r') as f:\n",
    "    qrs = json.load(f)\n",
    "\n",
    "with open(f\"{dir2barcodes}/splits.json\", 'r') as f:\n",
    "    barcodes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = {\"categories\":publaynet[\"categories\"].copy(),\n",
    "            \"images\":[],\n",
    "            \"annotations\":[]}\n",
    "\n",
    "dataset[\"categories\"].append({'supercategory': '', 'id': 6, 'name': 'signature'})\n",
    "dataset[\"categories\"].append({'supercategory': '', 'id': 7, 'name': 'stamp'})\n",
    "dataset[\"categories\"].append({'supercategory': '', 'id': 8, 'name': 'qr'})\n",
    "dataset[\"categories\"].append({'supercategory': '', 'id': 9, 'name': 'barcode'})\n",
    "# dataset[\"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, sample in tqdm(enumerate(publaynet[\"images\"])):     \n",
    "    dataset[\"annotations\"].append(get_all_annotations_from_image(publaynet, int(sample[\"id\"])))\n",
    "    \n",
    "    l0 = cv2.imread(f\"{dir2publaynet}/train/{sample['file_name']}\")\n",
    "    l0 = cv2.cvtColor(l0, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    all = l0.copy()\n",
    "    l1 = np.ones_like(l0) * 255\n",
    "    \n",
    "    # n = np.random.randint(1, 4)\n",
    "    # imgs, dataset = add_stamps(n, [all, l1], stamps, dir2stamps, dataset, sample['id'])\n",
    "    # all, l1 = imgs\n",
    "\n",
    "    n = np.random.randint(0, 5)\n",
    "    imgs, dataset = add_signatures(n, [all, l1], signatures, dir2signatures, dataset, sample['id'])\n",
    "    all, l1 = imgs\n",
    "    \n",
    "    # n = np.random.randint(0, 3)\n",
    "    # imgs, dataset = add_qrs(n, [all, l1], qrs, dir2qrs, dataset, sample['id'])\n",
    "    # all, l1 = imgs\n",
    "    \n",
    "    # n = np.random.randint(0, 2)\n",
    "    # imgs, dataset = add_barcodes(n, [all, l1], barcodes, dir2barcodes, dataset, sample['id'])\n",
    "    # all, l1 = imgs\n",
    "    \n",
    "    # if random.choice([True, False]):\n",
    "    #     imgs = add_bkg_noise([all, l1])\n",
    "    #     all, l1 = imgs\n",
    "    \n",
    "    # if random.choice([True, False, False, False, False, False]):\n",
    "    #     imgs = add_border(dir_borders, [all, l0, l1])\n",
    "    #     all, l0, l1 = imgs\n",
    "        \n",
    "    # img = add_lighting_and_yellow_tint([all, l1])\n",
    "    # all, l1 = img\n",
    "    \n",
    "    # Save the image\n",
    "    # os.makedirs(f\"{ds_dir}/{split}\", exist_ok=True)\n",
    "\n",
    "    # show the 3 images\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    ax[0].imshow(all)\n",
    "    ax[1].imshow(l0)\n",
    "    ax[2].imshow(l1)\n",
    "    plt.show()\n",
    "    break\n",
    "    \n",
    "    cv2.imwrite(f\"{ds_dir}/{split}/{sample['file_name']}\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "    # print(f\"Image {sample['file_name']} saved\")\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        with open(f\"{ds_dir}/{split}.json\", 'w') as f:\n",
    "            json.dump(dataset, f)\n",
    "        print(f\"Dataset saved at {ds_dir}/{split}.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"images\"] = publaynet[\"images\"]\n",
    "\n",
    "#remove all [] from the annotations list\n",
    "dataset[\"annotations\"] = [item for item in dataset[\"annotations\"] if item != []]\n",
    "\n",
    "with open(f\"{ds_dir}/{split}.json\", 'w') as f:\n",
    "    json.dump(dataset, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
