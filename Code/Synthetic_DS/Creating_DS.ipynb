{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signatures preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir2signatures = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/qrs_dataset/\"\n",
    "dataset = \"dataset3\"\n",
    "\n",
    "# read all images and split them into train, val and test\n",
    "import os\n",
    "\n",
    "# images = os.listdir(f\"{dir2qrs}/{dataset}/forge\")\n",
    "# # images = [img for img in images if img.endswith(\".jpg\")]\n",
    "\n",
    "# import random\n",
    "\n",
    "# random.shuffle(images)\n",
    "\n",
    "# train_images = images[:int(0.8 * len(images))]\n",
    "# val_images = images[int(0.8 * len(images)):int(0.9 * len(images))]\n",
    "# test_images = images[int(0.9 * len(images)):]\n",
    "\n",
    "# create json files\n",
    "data = []\n",
    "for img in train_images:\n",
    "    data.append({\"file_name\": img, \"split\": \"train\"})\n",
    "    \n",
    "for img in val_images:\n",
    "    data.append({\"file_name\": img, \"split\": \"val\"})\n",
    "    \n",
    "for img in test_images:\n",
    "    data.append({\"file_name\": img, \"split\": \"test\"})\n",
    "    \n",
    "with open(f\"{dir2qrs}ds3_splits.json\", 'w') as f:\n",
    "    json.dump(data, f)\n",
    "    \n",
    "\n",
    "print(f\"Number of train images: {len(train_images)}\")\n",
    "print(f\"Number of val images: {len(val_images)}\")\n",
    "print(f\"Number of test images: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dir2qrs = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Signatures_dataset/\"\n",
    "dataset = \"dataset3\"\n",
    "\n",
    "with open(f\"{dir2qrs}ds3_splits.json\", 'r') as f:\n",
    "    qrs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax, fig = plt.subplots(4, 4, figsize=(12, 7))\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        img = plt.imread(f\"{dir2qrs}/{dataset}/forge/{qrs[i*4+j]['file_name']}\")\n",
    "        fig[i, j].imshow(img, cmap='gray')\n",
    "        fig[i, j].axis('off')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ax, fig = plt.subplots(1, 2, figsize=(12, 7))\n",
    "\n",
    "# Load image, convert to grayscale, Gaussian blur, Otsu's threshold\n",
    "image = cv2.imread(f\"{dir2signatures}/{dataset}/forge/{qrs[0]['file_name']}\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Bitwise-and and color background white\n",
    "result = cv2.bitwise_and(image, image, mask=thresh)\n",
    "result[thresh==0] = [255,255,255]\n",
    "\n",
    "fig[0].imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "fig[0].axis('off')\n",
    "fig[0].set_title('Preprocessed Image')\n",
    "\n",
    "fig[1].imshow(thresh, cmap='gray')\n",
    "fig[1].axis('off')\n",
    "fig[1].set_title('Thresholded Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_signature(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Bitwise-and and color background white\n",
    "    result = cv2.bitwise_and(gray, gray, mask=thresh)\n",
    "    result[thresh==0] = 255\n",
    "\n",
    "    # add an alpha channel to the image\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_GRAY2RGBA)\n",
    "    result[:, :, 3] = thresh\n",
    "\n",
    "    return result, thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir2signatures = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Signatures_dataset/\"\n",
    "dataset = \"dataset3\"\n",
    "\n",
    "# Get the list of image files\n",
    "image_files = os.listdir(f\"{dir2signatures}/{dataset}/forge\")\n",
    "\n",
    "# Iterate over the image files\n",
    "for image_file in image_files:\n",
    "    # Get the image path\n",
    "    image_path = f\"{dir2signatures}/{dataset}/forge/{image_file}\"\n",
    "    \n",
    "    # Preprocess the image\n",
    "    result, mask = preprocess_signature(image_path)\n",
    "    \n",
    "    # Plot the original image, mask, and result\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    # Plot the original image\n",
    "    original_image = cv2.imread(image_path)\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    axes[0].imshow(original_image)\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Plot the mask\n",
    "    axes[1].imshow(mask, cmap='gray')\n",
    "    axes[1].set_title('Mask')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Plot the result\n",
    "    axes[2].imshow(result, cmap='gray')\n",
    "    axes[2].set_title('Result')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir2signatures = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Signatures_dataset/\"\n",
    "dataset = \"dataset3\"\n",
    "\n",
    "# Get the list of image files\n",
    "image_files = os.listdir(f\"{dir2signatures}/{dataset}/forge\")\n",
    "\n",
    "# Iterate over the image files\n",
    "for image_file in image_files:\n",
    "    # Get the image path\n",
    "    image_path = f\"{dir2signatures}/{dataset}/forge/{image_file}\"\n",
    "    \n",
    "    # Preprocess the image\n",
    "    result, mask = preprocess_signature(image_path)\n",
    "    \n",
    "    # Save the result\n",
    "    os.makedirs(f\"{dir2signatures}/{dataset}/forge_preprocessed\", exist_ok=True)\n",
    "    print(f\"Saving image: {image_file[:-4]}.png\")\n",
    "    cv2.imwrite(f\"{dir2signatures}/{dataset}/forge_preprocessed/{image_file[:-4]}.png\", result, [int(cv2.IMWRITE_PNG_COMPRESSION), 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding it to the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transparent_image(background, foreground, x_offset=None, y_offset=None):\n",
    "    bg_h, bg_w, bg_channels = background.shape\n",
    "    fg_h, fg_w, fg_channels = foreground.shape\n",
    "\n",
    "    assert bg_channels == 3, f'background image should have exactly 3 channels (RGB). found:{bg_channels}'\n",
    "    assert fg_channels == 4, f'foreground image should have exactly 4 channels (RGBA). found:{fg_channels}'\n",
    "\n",
    "    # center by default\n",
    "    if x_offset is None: x_offset = (bg_w - fg_w) // 2\n",
    "    if y_offset is None: y_offset = (bg_h - fg_h) // 2\n",
    "\n",
    "    w = min(fg_w, bg_w, fg_w + x_offset, bg_w - x_offset)\n",
    "    h = min(fg_h, bg_h, fg_h + y_offset, bg_h - y_offset)\n",
    "\n",
    "    if w < 1 or h < 1: return\n",
    "\n",
    "    # clip foreground and background images to the overlapping regions\n",
    "    bg_x = max(0, x_offset)\n",
    "    bg_y = max(0, y_offset)\n",
    "    fg_x = max(0, x_offset * -1)\n",
    "    fg_y = max(0, y_offset * -1)\n",
    "    foreground = foreground[fg_y:fg_y + h, fg_x:fg_x + w]\n",
    "    background_subsection = background[bg_y:bg_y + h, bg_x:bg_x + w]\n",
    "\n",
    "    # separate alpha and color channels from the foreground image\n",
    "    foreground_colors = foreground[:, :, :3]\n",
    "    alpha_channel = foreground[:, :, 3] / 255  # 0-255 => 0.0-1.0\n",
    "\n",
    "    # construct an alpha_mask that matches the image shape\n",
    "    alpha_mask = np.dstack((alpha_channel, alpha_channel, alpha_channel))\n",
    "\n",
    "    # combine the background with the overlay image weighted by alpha\n",
    "    composite = background_subsection * (1 - alpha_mask) + foreground_colors * alpha_mask\n",
    "\n",
    "    # overwrite the section of the background image that has been updated\n",
    "    background[bg_y:bg_y + h, bg_x:bg_x + w] = composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = f\"{dir2publaynet}/{split}/{sample['file_name']}\"\n",
    "\n",
    "background = cv2.imread(page)\n",
    "background = cv2.cvtColor(background, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# resize the signature to 1/4 of the page\n",
    "overlay = cv2.resize(result, (0,0), fx=0.25, fy=0.25)\n",
    "mask = cv2.resize(thresh, (0,0), fx=0.25, fy=0.25)\n",
    "\n",
    "overlay = cv2.cvtColor(overlay, cv2.COLOR_RGB2RGBA)\n",
    "overlay[:, :, 3] = mask\n",
    "\n",
    "img = background.copy()\n",
    "add_transparent_image(img, overlay, 50, 50)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = f\"{dir2publaynet}/{split}/{sample['file_name']}\"\n",
    "\n",
    "background = cv2.imread(page)\n",
    "background = cv2.cvtColor(background, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "overlay = cv2.imread(f\"{dir2signatures}/{dataset}/forge_preprocessed/{image_files[0][:-4]}.png\", cv2.IMREAD_UNCHANGED)\n",
    "overlay = cv2.resize(result, (0,0), fx=0.25, fy=0.25)\n",
    "\n",
    "img = background.copy()\n",
    "add_transparent_image(img, overlay, 50, 50)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision.transforms as v2\n",
    "# import torchvision\n",
    "\n",
    "# transforms = v2.Compose([\n",
    "#     v2.ToPILImage(),\n",
    "#     v2.RandomRotation(degrees=30),\n",
    "#     v2.Resize(224)])\n",
    "#     # v2.RandomResizedCrop(224)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "dir2signatures = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Signatures_dataset/\"\n",
    "dataset = \"dataset3/forge_preprocessed\"\n",
    "\n",
    "dir2publaynet = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Publaynet\"\n",
    "split = \"train\"\n",
    "\n",
    "with open(f\"{dir2signatures}ds3_splits.json\", 'r') as f:\n",
    "    signatures = json.load(f)\n",
    "    \n",
    "with open(\"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Code/Synthetic_DS/train_syn.json\", 'r') as f:\n",
    "    publaynet = json.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the publaynet 100 first images and place 3 signatures on each image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for i, sample in enumerate(publaynet[:10]):\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    # Load the page image\n",
    "    page = cv2.imread(f\"{dir2publaynet}/{split}/{sample['file_name']}\")\n",
    "    page = cv2.cvtColor(page, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create a copy of the page image\n",
    "    img = page.copy()\n",
    "    \n",
    "    # Iterate over the signatures\n",
    "    for j in range(3):\n",
    "        idx = np.random.randint(0, len(signatures))\n",
    "        \n",
    "        # Get the signature image\n",
    "        signature = cv2.imread(f\"{dir2signatures}/{dataset}/{signatures[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "        # signature = cv2.cvtColor(signature, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Resize the signature image\n",
    "        size = np.random.randint(50, 200)\n",
    "        signature = cv2.resize(signature, (0,0), fx=size/signature.shape[1], fy=size/signature.shape[0])\n",
    "        \n",
    "        # rotate the image randomly\n",
    "        angle = np.random.randint(-30, 30)\n",
    "        center = (signature.shape[1]//2, signature.shape[0]//2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "        signature = cv2.warpAffine(signature, M, (signature.shape[1], signature.shape[0]))\n",
    "        \n",
    "        \n",
    "        x_offset = np.random.randint(0, page.shape[1] - signature.shape[1])\n",
    "        y_offset = np.random.randint(0, page.shape[0] - signature.shape[0])\n",
    "        # Add the signature to the page image\n",
    "        add_transparent_image(img, signature, x_offset, y_offset)\n",
    "        \n",
    "    # Save the image\n",
    "    # os.makedirs(f\"{dir2publaynet}/{split}_syn\", exist_ok=True)\n",
    "    # cv2.imwrite(f\"{dir2publaynet}/{split}_syn/{sample['file_name']}\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # print(f\"Saved image {i+1} of 100\")\n",
    "    \n",
    "    # if i == 10:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stamps preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "stamps_ds = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Stamps_dataset/non-preprocessed\"\n",
    "stamps_list = os.listdir(stamps_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(10, 10, figsize=(20, 20))\n",
    "\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i in range(100):\n",
    "    img = plt.imread(f\"{stamps_ds}/{stamps_list[i]}\")\n",
    "    ax[i].imshow(img, cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, ax = plt.subplots(len(), 3, figsize=(12, 40))\n",
    "\n",
    "# ax = ax.flatten()\n",
    "\n",
    "def remove_background(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    mask_inv = cv2.bitwise_not(thresh)\n",
    "    result = cv2.bitwise_and(image, image, mask=mask_inv)\n",
    "    \n",
    "    return image, result, thresh\n",
    "\n",
    "\n",
    "os.makedirs(f\"{stamps_ds}/preprocessed\", exist_ok=True)\n",
    "for i in range(len(stamps_list)):\n",
    "    try: \n",
    "        print(f\"Processing image {stamps_list[i]}\")\n",
    "        img, result, mask = remove_background(f\"{stamps_ds}/{stamps_list[i]}\")\n",
    "        \n",
    "        cv2.imwrite(f\"{stamps_ds}/preprocessed/{stamps_list[i]}\", result, [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
    "    \n",
    "    \n",
    "    #     ax[3*i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    #     ax[3*i].set_title('Original Image')\n",
    "    #     ax[3*i].axis('off')\n",
    "        \n",
    "    #     ax[(3*i)+1].imshow(mask, cmap='gray')\n",
    "    #     ax[(3*i)+1].set_title('Mask')\n",
    "    #     ax[(3*i)+1].axis('off')\n",
    "        \n",
    "    #     ax[(3*i)+2].imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    #     ax[(3*i)+2].set_title('Result')\n",
    "    #     ax[(3*i)+2].axis('off')\n",
    "    except: \n",
    "        print(f\"Error processing image {stamps_list[i]}\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_processed = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Stamps_dataset/non-preprocessed\"\n",
    "processed = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Stamps_dataset/preprocessed\"\n",
    "\n",
    "# check if every image has been processed otherwise copy the original image to the processed folder\n",
    "import shutil\n",
    "\n",
    "non_processed_list = os.listdir(non_processed)\n",
    "processed_list = os.listdir(processed)\n",
    "\n",
    "for img in non_processed_list:\n",
    "    if img not in processed_list:\n",
    "        shutil.copy(f\"{non_processed}/{img}\", processed)\n",
    "        print(f\"Copying {img} to processed folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "dir2stamps = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Stamps_dataset/preprocessed\"\n",
    "\n",
    "images = os.listdir(f\"{dir2stamps}\")\n",
    "\n",
    "import random\n",
    "random.shuffle(images)\n",
    "\n",
    "train_images = images[:int(0.8 * len(images))]\n",
    "val_images = images[int(0.8 * len(images)):int(0.9 * len(images))]\n",
    "test_images = images[int(0.9 * len(images)):]\n",
    "\n",
    "# create json files\n",
    "data = []\n",
    "for img in train_images:\n",
    "    data.append({\"file_name\": img, \"split\": \"train\"})\n",
    "    \n",
    "for img in val_images:\n",
    "    data.append({\"file_name\": img, \"split\": \"val\"})\n",
    "    \n",
    "for img in test_images:\n",
    "    data.append({\"file_name\": img, \"split\": \"test\"})\n",
    "    \n",
    "with open(f\"{dir2stamps}/splits.json\", 'w') as f:\n",
    "    json.dump(data, f)\n",
    "    \n",
    "\n",
    "print(f\"Number of train images: {len(train_images)}\")\n",
    "print(f\"Number of val images: {len(val_images)}\")\n",
    "print(f\"Number of test images: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding them to pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "dir2stamps = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Stamps_dataset/preprocessed\"\n",
    "\n",
    "dir2publaynet = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Publaynet\"\n",
    "split = \"train\"\n",
    "\n",
    "dir2signatures = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Signatures_dataset/\"\n",
    "dataset = \"dataset3/forge_preprocessed\"\n",
    "\n",
    "\n",
    "with open(\"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Stamps_dataset/splits.json\", 'r') as f:\n",
    "    stamps = json.load(f)\n",
    "    \n",
    "with open(\"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Code/Synthetic_DS/train_syn.json\", 'r') as f:\n",
    "    publaynet = json.load(f)   \n",
    "    \n",
    "with open(f\"{dir2signatures}ds3_splits.json\", 'r') as f:\n",
    "    signatures = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stamps(n, page, stamps, stamps_ds):\n",
    "    img = page.copy()\n",
    "    j = 0\n",
    "    while j < n:\n",
    "        idx = np.random.randint(0, len(stamp))\n",
    "        if stamp[idx]['split'] != 'train':\n",
    "            continue\n",
    "        try: \n",
    "            idx = np.random.randint(0, len(stamps))\n",
    "            stamp = cv2.imread(f\"{stamps_ds}/{stamps[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "            stamp = cv2.cvtColor(stamp, cv2.COLOR_BGR2RGBA)\n",
    "            \n",
    "            size = np.random.normal(200, 200)\n",
    "            size = int(np.clip(size, 50, page.shape[1]))\n",
    "            stamp = cv2.resize(stamp, (0,0), fx=size/stamp.shape[1], fy=size/stamp.shape[0])\n",
    "            \n",
    "            angle = np.random.randint(-30, 30)\n",
    "            center = (stamp.shape[1]//2, stamp.shape[0]//2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "            stamp = cv2.warpAffine(stamp, M, (stamp.shape[1], stamp.shape[0]))\n",
    "            \n",
    "            x_offset = np.random.randint(0, page.shape[1] - stamp.shape[1])\n",
    "            y_offset = np.random.randint(0, page.shape[0] - stamp.shape[0])\n",
    "            \n",
    "            alpha = np.random.normal(1-(1/(page.shape[1]/size)), 0.2)\n",
    "            # print(f\"alpha: {0.8-(1/(page.shape[1]/size))}\")\n",
    "            alpha = np.clip(alpha, 0.1, 1)\n",
    "            \n",
    "            add_transparent_image(img, stamp*alpha, x_offset, y_offset)\n",
    "            j += 1\n",
    "            \n",
    "            cv2.rectangle(img, (x_offset, y_offset), (x_offset+stamp.shape[1], y_offset+stamp.shape[0]), (0, 255, 0), 4)\n",
    "        except:\n",
    "            print(f\"Error adding stamp {stamps[idx]['file_name']}\")\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_signatures(n, page, signatures, signatures_ds):\n",
    "    img = page.copy()\n",
    "        \n",
    "    j = 0\n",
    "    while j < n:\n",
    "        idx = np.random.randint(0, len(signatures))\n",
    "        if signatures[idx]['split'] != 'train':\n",
    "            continue\n",
    "        try: \n",
    "            signature = cv2.imread(f\"{dir2signatures}/{dataset}/{signatures[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            size = np.random.randint(50, 200)\n",
    "            signature = cv2.resize(signature, (0,0), fx=size/signature.shape[1], fy=size/signature.shape[0])\n",
    "            \n",
    "            # rotate the image randomly\n",
    "            angle = np.random.randint(-30, 30)\n",
    "            center = (signature.shape[1]//2, signature.shape[0]//2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "            signature = cv2.warpAffine(signature, M, (signature.shape[1], signature.shape[0]))\n",
    "            \n",
    "            \n",
    "            x_offset = np.random.randint(0, page.shape[1] - signature.shape[1])\n",
    "            y_offset = np.random.randint(0, page.shape[0] - signature.shape[0])\n",
    "\n",
    "            # alpha = np.random.normal(0.9, 0.2)\n",
    "            alpha = 1\n",
    "            \n",
    "            add_transparent_image(img, signature*alpha, x_offset, y_offset)\n",
    "            j += 1\n",
    "            \n",
    "            cv2.rectangle(img, (x_offset, y_offset), (x_offset+signature.shape[1], y_offset+signature.shape[0]), (255, 0, 255), 3)\n",
    "        except:\n",
    "            print(f\"Error adding signature {signatures[idx]['file_name']}\")\n",
    "            \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the publaynet 100 first images and place 3 signatures on each image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for i, sample in enumerate(publaynet[:10]):\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    # Load the page image\n",
    "    page = cv2.imread(f\"{dir2publaynet}/{split}/{sample['file_name']}\")\n",
    "    page = cv2.cvtColor(page, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    n = np.random.randint(1, 4)\n",
    "    img = add_stamps(n, page, stamps, dir2stamps)\n",
    "    \n",
    "    n = np.random.randint(1, 4)\n",
    "    img = add_signatures(n, img, signatures, dir2signatures)\n",
    "        \n",
    "    # Save the image\n",
    "    # os.makedirs(f\"{dir2publaynet}/{split}_syn\", exist_ok=True)\n",
    "    # cv2.imwrite(f\"{dir2publaynet}/{split}_syn/{sample['file_name']}\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install qrcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qrcode\n",
    "from PIL import Image\n",
    "\n",
    "def generate_qr_code(data, filename):\n",
    "    qr = qrcode.QRCode(\n",
    "        version=1,\n",
    "        error_correction=qrcode.constants.ERROR_CORRECT_L,\n",
    "        box_size=10,\n",
    "        border=4,\n",
    "    )\n",
    "    qr.add_data(data)\n",
    "    qr.make(fit=True)\n",
    "\n",
    "    img = qr.make_image(fill_color=\"black\", back_color=\"white\")\n",
    "    img.save(filename)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import string\n",
    "\n",
    "qr_dataset = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/QRs_dataset/\"\n",
    "\n",
    "# Generate a dataset of QR codes\n",
    "dataset_size = 150\n",
    "for i in range(dataset_size):\n",
    "    # Generate a random URL with random length and characters\n",
    "    data = ''.join(random.choices(string.ascii_uppercase + string.digits, k=random.randint(10, 50)))\n",
    "    filename = f\"QRCode_{i}.png\"  # Output filename\n",
    "    generate_qr_code(data, qr_dataset + \"non-preprocessed/\" + filename)\n",
    "\n",
    "    # Load the QR code image\n",
    "    qr_image = cv2.imread(qr_dataset + \"non-preprocessed/\" + filename)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(qr_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to create a binary mask\n",
    "    _, mask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Invert the mask\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    result = cv2.bitwise_and(qr_image, qr_image, mask=mask_inv)\n",
    "    \n",
    "    result = cv2.cvtColor(result, cv2.COLOR_RGB2RGBA)\n",
    "    result[:, :, 3] = mask_inv\n",
    "\n",
    "    os.makedirs(qr_dataset + \"/preprocessed\", exist_ok=True)\n",
    "    cv2.imwrite(qr_dataset + \"/preprocessed/\" + filename, result, [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
    "\n",
    "    # Save the image without background\n",
    "    plt.imshow(result)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "dir2qrs = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/QRs_dataset/\"\n",
    "\n",
    "images = os.listdir(f\"{dir2qrs}/preprocessed\")\n",
    "\n",
    "import random\n",
    "random.shuffle(images)\n",
    "\n",
    "train_images = images[:int(0.8 * len(images))]\n",
    "val_images = images[int(0.8 * len(images)):int(0.9 * len(images))]\n",
    "test_images = images[int(0.9 * len(images)):]\n",
    "\n",
    "# create json files\n",
    "data = []\n",
    "for img in train_images:\n",
    "    data.append({\"file_name\": img, \"split\": \"train\"})\n",
    "    \n",
    "for img in val_images:\n",
    "    data.append({\"file_name\": img, \"split\": \"val\"})\n",
    "    \n",
    "for img in test_images:\n",
    "    data.append({\"file_name\": img, \"split\": \"test\"})\n",
    "    \n",
    "with open(f\"{dir2qrs}/splits.json\", 'w') as f:\n",
    "    json.dump(data, f)\n",
    "    \n",
    "\n",
    "print(f\"Number of train images: {len(train_images)}\")\n",
    "print(f\"Number of val images: {len(val_images)}\")\n",
    "print(f\"Number of test images: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_qrs(n, page, qrs, qrs_dataset):\n",
    "    img = page.copy()\n",
    "        \n",
    "    j = 0\n",
    "    while j < n:\n",
    "        idx = np.random.randint(0, len(qrs))\n",
    "        if qrs[idx]['split'] != 'train':\n",
    "            continue\n",
    "        try: \n",
    "            \n",
    "            # print(f\"Adding QR code {qrs_dataset}/preprocessed/{qrs[idx]['file_name']}\")\n",
    "            \n",
    "            qr = cv2.imread(f\"{qrs_dataset}/preprocessed/{qrs[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "            # crop a 5 % of the image per each side\n",
    "            qr = qr[qr.shape[0]//10:qr.shape[0]-(qr.shape[0]//10), qr.shape[1]//10:qr.shape[1]-(qr.shape[1]//10)]\n",
    "\n",
    "\n",
    "            size = np.random.randint(50, 175)\n",
    "            qr = cv2.resize(qr, (0,0), fx=size/qr.shape[1], fy=size/qr.shape[0])\n",
    "            \n",
    "            x_offset = np.random.randint(0, page.shape[1] - qr.shape[1])\n",
    "            y_offset = np.random.randint(0, page.shape[0] - qr.shape[0])\n",
    "\n",
    "            alpha = np.random.normal(0.9, 0.2)\n",
    "            alpha = np.clip(alpha, 0.1, 1)\n",
    "            \n",
    "            add_transparent_image(img, qr*alpha, x_offset, y_offset)\n",
    "            j += 1\n",
    "            \n",
    "            cv2.rectangle(img, (x_offset, y_offset), (x_offset+qr.shape[1], y_offset+qr.shape[0]), (0, 0, 255), 3)\n",
    "        except:\n",
    "            print(f\"Error adding qr {qrs[idx]['file_name']}\")\n",
    "            raise(Exception)\n",
    "            \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir2qrs = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/QRs_dataset\"\n",
    "\n",
    "with open(f\"{dir2qrs}/splits.json\", 'r') as f:\n",
    "    qrs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the publaynet 100 first images and place 3 signatures on each image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for i, sample in enumerate(publaynet[:10]):\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    # Load the page image\n",
    "    \n",
    "    page = cv2.imread(f\"{dir2publaynet}/{split}/{sample['file_name']}\")\n",
    "    page = cv2.cvtColor(page, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    n = np.random.randint(1, 4)\n",
    "    img = add_stamps(n, page, stamps, dir2stamps)\n",
    "    \n",
    "    n = np.random.randint(1, 4)\n",
    "    img = add_signatures(n, img, signatures, dir2signatures)\n",
    "    \n",
    "    n = np.random.randint(1, 4)\n",
    "    img = add_qrs(n, img, qrs, dir2qrs)\n",
    "    \n",
    "    # Save the image\n",
    "    # os.makedirs(f\"{dir2publaynet}/{split}_syn\", exist_ok=True)\n",
    "    # cv2.imwrite(f\"{dir2publaynet}/{split}_syn/{sample['file_name']}\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import barcode\n",
    "from barcode.writer import ImageWriter\n",
    "import random\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_barcode(data, filename):\n",
    "    # Generate random data of random length and characters\n",
    "    \n",
    "    barcode_class = barcode.get_barcode_class('code128')\n",
    "    barcode_image = barcode_class(data, writer=ImageWriter())\n",
    "\n",
    "    # Save the barcode image\n",
    "    barcode_image.save(filename)\n",
    "\n",
    "    return barcode_image\n",
    "\n",
    "# Directory for saving the barcode images\n",
    "barcode_dataset = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Barcodes_dataset/\"\n",
    "os.makedirs(os.path.join(barcode_dataset, \"non-preprocessed\"), exist_ok=True)\n",
    "\n",
    "# Generate a dataset of barcodes\n",
    "dataset_size = 150\n",
    "for i in range(dataset_size):\n",
    "    data = ''.join(random.choices(string.ascii_uppercase + string.digits, k=random.randint(10, 50)))\n",
    "    filename = f\"Barcode_{i}\"  # Output filename\n",
    "    generate_barcode(data, os.path.join(barcode_dataset, \"non-preprocessed\", filename))\n",
    "\n",
    "    # Load the barcode image\n",
    "    barcode_image = cv2.imread(os.path.join(barcode_dataset, \"non-preprocessed\", filename) + \".png\")\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(barcode_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to create a binary mask\n",
    "    _, mask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Invert the mask\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    result = cv2.bitwise_and(barcode_image, barcode_image, mask=mask_inv)\n",
    "    \n",
    "    result = cv2.cvtColor(result, cv2.COLOR_RGB2RGBA)\n",
    "    result[:, :, 3] = mask_inv\n",
    "\n",
    "    # Save the preprocessed image without background\n",
    "    os.makedirs(os.path.join(barcode_dataset, \"preprocessed\"), exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(barcode_dataset, \"preprocessed\", filename + \".png\"), result, [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
    "\n",
    "    # Display the preprocessed image\n",
    "    plt.imshow(result)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "dir2barcodes = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Barcodes_dataset/\"\n",
    "\n",
    "images = os.listdir(f\"{dir2barcodes}/preprocessed\")\n",
    "\n",
    "import random\n",
    "random.shuffle(images)\n",
    "\n",
    "train_images = images[:int(0.8 * len(images))]\n",
    "val_images = images[int(0.8 * len(images)):int(0.9 * len(images))]\n",
    "test_images = images[int(0.9 * len(images)):]\n",
    "\n",
    "# create json files\n",
    "data = []\n",
    "for img in train_images:\n",
    "    data.append({\"file_name\": img, \"split\": \"train\"})\n",
    "    \n",
    "for img in val_images:\n",
    "    data.append({\"file_name\": img, \"split\": \"val\"})\n",
    "    \n",
    "for img in test_images:\n",
    "    data.append({\"file_name\": img, \"split\": \"test\"})\n",
    "    \n",
    "with open(f\"{dir2barcodes}/splits.json\", 'w') as f:\n",
    "    json.dump(data, f)\n",
    "    \n",
    "\n",
    "print(f\"Number of train images: {len(train_images)}\")\n",
    "print(f\"Number of val images: {len(val_images)}\")\n",
    "print(f\"Number of test images: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_barcodes(n, page, barcodes, barcodes_dataset):\n",
    "    img = page.copy()\n",
    "        \n",
    "    j = 0\n",
    "    while j < n:\n",
    "        idx = np.random.randint(0, len(qrs))\n",
    "        if qrs[idx]['split'] != 'train':\n",
    "            continue\n",
    "        try: \n",
    "            \n",
    "            # print(f\"Adding QR code {qrs_dataset}/preprocessed/{qrs[j]['file_name']}\")\n",
    "            \n",
    "            barcode = cv2.imread(f\"{barcodes_dataset}/preprocessed/{barcodes[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "            # crop a 5 % of the image per each side\n",
    "            # barcode = barcode[qr.shape[0]//10:qr.shape[0]-(qr.shape[0]//10), qr.shape[1]//10:barcode.shape[1]-(barcode.shape[1]//10)]\n",
    "\n",
    "\n",
    "            size = np.random.randint(50, 175)\n",
    "            barcode = cv2.resize(barcode, (0,0), fx=size/barcode.shape[1], fy=size/barcode.shape[0])\n",
    "            \n",
    "            x_offset = np.random.randint(0, page.shape[1] - barcode.shape[1])\n",
    "            y_offset = np.random.randint(0, page.shape[0] - barcode.shape[0])\n",
    "\n",
    "            alpha = np.random.normal(0.9, 0.2)\n",
    "            alpha = np.clip(alpha, 0.1, 1)\n",
    "            \n",
    "            add_transparent_image(img, barcode*alpha, x_offset, y_offset)\n",
    "            j += 1\n",
    "            \n",
    "            cv2.rectangle(img, (x_offset, y_offset), (x_offset+barcode.shape[1], y_offset+barcode.shape[0]), (0, 255, 255), 3)\n",
    "        except:\n",
    "            print(f\"Error adding barcode {barcodes[idx]['file_name']}\")\n",
    "            raise(Exception)\n",
    "            \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir2barcodes = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Barcodes_dataset\"\n",
    "\n",
    "with open(f\"{dir2barcodes}/splits.json\", 'r') as f:\n",
    "    barcodes = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transparent_image(background, foreground, x_offset=None, y_offset=None):\n",
    "    bg_h, bg_w, bg_channels = background.shape\n",
    "    fg_h, fg_w, fg_channels = foreground.shape\n",
    "\n",
    "    assert bg_channels == 3, f'background image should have exactly 3 channels (RGB). found:{bg_channels}'\n",
    "    assert fg_channels == 4, f'foreground image should have exactly 4 channels (RGBA). found:{fg_channels}'\n",
    "\n",
    "    # center by default\n",
    "    if x_offset is None: x_offset = (bg_w - fg_w) // 2\n",
    "    if y_offset is None: y_offset = (bg_h - fg_h) // 2\n",
    "\n",
    "    w = min(fg_w, bg_w, fg_w + x_offset, bg_w - x_offset)\n",
    "    h = min(fg_h, bg_h, fg_h + y_offset, bg_h - y_offset)\n",
    "\n",
    "    if w < 1 or h < 1: return\n",
    "\n",
    "    # clip foreground and background images to the overlapping regions\n",
    "    bg_x = max(0, x_offset)\n",
    "    bg_y = max(0, y_offset)\n",
    "    fg_x = max(0, x_offset * -1)\n",
    "    fg_y = max(0, y_offset * -1)\n",
    "    foreground = foreground[fg_y:fg_y + h, fg_x:fg_x + w]\n",
    "    background_subsection = background[bg_y:bg_y + h, bg_x:bg_x + w]\n",
    "\n",
    "    # separate alpha and color channels from the foreground image\n",
    "    foreground_colors = foreground[:, :, :3]\n",
    "    alpha_channel = foreground[:, :, 3] / 255  # 0-255 => 0.0-1.0\n",
    "\n",
    "    # construct an alpha_mask that matches the image shape\n",
    "    alpha_mask = np.dstack((alpha_channel, alpha_channel, alpha_channel))\n",
    "\n",
    "    # combine the background with the overlay image weighted by alpha\n",
    "    composite = background_subsection * (1 - alpha_mask) + foreground_colors * alpha_mask\n",
    "\n",
    "    # overwrite the section of the background image that has been updated\n",
    "    background[bg_y:bg_y + h, bg_x:bg_x + w] = composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_COCO_annotation(dataset, image_id, category_id, x, y, w, h):\n",
    "    # print(dataset)\n",
    "    annotation = {\n",
    "        \"area\": w * h,\n",
    "        \"iscrowd\": 0,\n",
    "        \"image_id\": image_id,\n",
    "        \"bbox\": [x, y, w, h],\n",
    "        \"category_id\": category_id, \n",
    "        \"id\": len(dataset[\"annotations\"]) + 1,\n",
    "    }\n",
    "    \n",
    "    dataset[\"annotations\"].append(annotation)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stamps(n, page, stamps, stamps_ds, dataset, image_id):\n",
    "    label = 7\n",
    "    \n",
    "    img = page.copy()\n",
    "    \n",
    "    j = 0\n",
    "    while j < n:\n",
    "        idx = np.random.randint(0, len(stamps))\n",
    "        if stamps[idx]['split'] != 'train':\n",
    "            continue\n",
    "        try: \n",
    "            stamp = cv2.imread(f\"{stamps_ds}/preprocessed/{stamps[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "            stamp = cv2.cvtColor(stamp, cv2.COLOR_BGR2RGBA)\n",
    "            \n",
    "            size = np.random.normal(200, 200)\n",
    "            size = int(np.clip(size, 50, page.shape[1]))\n",
    "            stamp = cv2.resize(stamp, (0,0), fx=size/stamp.shape[1], fy=size/stamp.shape[0])\n",
    "            \n",
    "            angle = np.random.randint(-30, 30)\n",
    "            center = (stamp.shape[1]//2, stamp.shape[0]//2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "            stamp = cv2.warpAffine(stamp, M, (stamp.shape[1], stamp.shape[0]))\n",
    "            \n",
    "            x_offset = np.random.randint(0, page.shape[1] - stamp.shape[1])\n",
    "            y_offset = np.random.randint(0, page.shape[0] - stamp.shape[0])\n",
    "            \n",
    "            alpha = np.random.normal(1-(1/(page.shape[1]/size)), 0.2)\n",
    "            # print(f\"alpha: {0.8-(1/(page.shape[1]/size))}\")\n",
    "            alpha = np.clip(alpha, 0.1, 1)\n",
    "            \n",
    "            add_transparent_image(img, stamp*alpha, x_offset, y_offset)\n",
    "            cv2.rectangle(img, (x_offset, y_offset), (x_offset+stamp.shape[1], y_offset+stamp.shape[0]), (0, 255, 0), 4)\n",
    "            \n",
    "            dataset = create_COCO_annotation(dataset, image_id, label, x_offset, y_offset, stamp.shape[1], stamp.shape[0])\n",
    "        \n",
    "            j += 1\n",
    "        except:\n",
    "            print(f\"Error adding stamp {stamps[idx]['file_name']}\")\n",
    "            raise(Exception)\n",
    "        \n",
    "    return img, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_signatures(n, page, signatures, signatures_ds, dataset, image_id):\n",
    "    label = 6\n",
    "    img = page.copy()\n",
    "        \n",
    "    j = 0\n",
    "    while j < n:\n",
    "        idx = np.random.randint(0, len(signatures))\n",
    "        if signatures[idx]['split'] != 'train':\n",
    "            continue\n",
    "        try: \n",
    "            print(f\"Adding signature {dir2signatures}/{dataset}/{signatures[idx]['file_name']}\")\n",
    "            signature = cv2.imread(f\"{dir2signatures}/{dataset}/{signatures[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            size = np.random.randint(50, 200)\n",
    "            signature = cv2.resize(signature, (0,0), fx=size/signature.shape[1], fy=size/signature.shape[0])\n",
    "            \n",
    "            # rotate the image randomly\n",
    "            angle = np.random.randint(-30, 30)\n",
    "            center = (signature.shape[1]//2, signature.shape[0]//2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "            signature = cv2.warpAffine(signature, M, (signature.shape[1], signature.shape[0]))\n",
    "            \n",
    "            \n",
    "            x_offset = np.random.randint(0, page.shape[1] - signature.shape[1])\n",
    "            y_offset = np.random.randint(0, page.shape[0] - signature.shape[0])\n",
    "\n",
    "            # alpha = np.random.normal(0.9, 0.2)\n",
    "            alpha = 1\n",
    "            \n",
    "            add_transparent_image(img, signature*alpha, x_offset, y_offset)\n",
    "            cv2.rectangle(img, (x_offset, y_offset), (x_offset+signature.shape[1], y_offset+signature.shape[0]), (255, 0, 255), 3)\n",
    "            \n",
    "            dataset = create_COCO_annotation(dataset, image_id, label, x_offset, y_offset, signature.shape[1], signature.shape[0])\n",
    "            \n",
    "            j += 1\n",
    "            \n",
    "        except:\n",
    "            print(f\"Error adding signature {signatures[idx]['file_name']}\")\n",
    "            raise(Exception)\n",
    "            \n",
    "    return img, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_qrs(n, page, qrs, qrs_dataset, dataset, image_id):\n",
    "    label = 8\n",
    "    img = page.copy()\n",
    "        \n",
    "    j = 0\n",
    "    while j < n:\n",
    "        idx = np.random.randint(0, len(qrs))\n",
    "        if qrs[idx]['split'] != 'train':\n",
    "            continue\n",
    "        try: \n",
    "            \n",
    "            # print(f\"Adding QR code {qrs_dataset}/preprocessed/{qrs[idx]['file_name']}\")\n",
    "            \n",
    "            qr = cv2.imread(f\"{qrs_dataset}/preprocessed/{qrs[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "            # crop a 5 % of the image per each side\n",
    "            qr = qr[qr.shape[0]//10:qr.shape[0]-(qr.shape[0]//10), qr.shape[1]//10:qr.shape[1]-(qr.shape[1]//10)]\n",
    "\n",
    "\n",
    "            size = np.random.randint(50, 175)\n",
    "            qr = cv2.resize(qr, (0,0), fx=size/qr.shape[1], fy=size/qr.shape[0])\n",
    "            \n",
    "            x_offset = np.random.randint(0, page.shape[1] - qr.shape[1])\n",
    "            y_offset = np.random.randint(0, page.shape[0] - qr.shape[0])\n",
    "\n",
    "            alpha = np.random.normal(0.9, 0.2)\n",
    "            alpha = np.clip(alpha, 0.1, 1)\n",
    "            \n",
    "            add_transparent_image(img, qr*alpha, x_offset, y_offset)\n",
    "            cv2.rectangle(img, (x_offset, y_offset), (x_offset+qr.shape[1], y_offset+qr.shape[0]), (0, 0, 255), 3)\n",
    "            \n",
    "            dataset = create_COCO_annotation(dataset, image_id, label, x_offset, y_offset, qr.shape[1], qr.shape[0])\n",
    "        \n",
    "            j += 1\n",
    "        except:\n",
    "            print(f\"Error adding qr {qrs[idx]['file_name']}\")\n",
    "            raise(Exception)\n",
    "            \n",
    "    return img, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_barcodes(n, page, barcodes, barcodes_dataset, dataset, image_id):\n",
    "    label = 9\n",
    "    img = page.copy()\n",
    "        \n",
    "    j = 0\n",
    "    while j < n:\n",
    "        idx = np.random.randint(0, len(qrs))\n",
    "        if qrs[idx]['split'] != 'train':\n",
    "            continue\n",
    "        try: \n",
    "            \n",
    "            # print(f\"Adding QR code {qrs_dataset}/preprocessed/{qrs[j]['file_name']}\")\n",
    "            \n",
    "            barcode = cv2.imread(f\"{barcodes_dataset}/preprocessed/{barcodes[idx]['file_name']}\", cv2.IMREAD_UNCHANGED)\n",
    "            # crop a 5 % of the image per each side\n",
    "            # barcode = barcode[qr.shape[0]//10:qr.shape[0]-(qr.shape[0]//10), qr.shape[1]//10:barcode.shape[1]-(barcode.shape[1]//10)]\n",
    "\n",
    "\n",
    "            size = np.random.randint(50, 175)\n",
    "            barcode = cv2.resize(barcode, (0,0), fx=size/barcode.shape[1], fy=size/barcode.shape[0])\n",
    "            \n",
    "            x_offset = np.random.randint(0, page.shape[1] - barcode.shape[1])\n",
    "            y_offset = np.random.randint(0, page.shape[0] - barcode.shape[0])\n",
    "\n",
    "            alpha = np.random.normal(0.9, 0.2)\n",
    "            alpha = np.clip(alpha, 0.1, 1)\n",
    "            \n",
    "            add_transparent_image(img, barcode*alpha, x_offset, y_offset)\n",
    "            cv2.rectangle(img, (x_offset, y_offset), (x_offset+barcode.shape[1], y_offset+barcode.shape[0]), (0, 255, 255), 3)\n",
    "            \n",
    "            dataset = create_COCO_annotation(dataset, image_id, label, x_offset, y_offset, barcode.shape[1], barcode.shape[0])\n",
    "            \n",
    "            j += 1\n",
    "        except:\n",
    "            print(f\"Error adding barcode {barcodes[idx]['file_name']}\")\n",
    "            raise(Exception)\n",
    "            \n",
    "    return img, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dir2publaynet = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Publaynet\"\n",
    "split = \"train\"\n",
    "\n",
    "dir2signatures = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Signatures_dataset/\"\n",
    "dataset = \"dataset3/forge_preprocessed\"\n",
    "\n",
    "dir2stamps = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Stamps_dataset\"\n",
    "dir2qrs = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/QRs_dataset\"\n",
    "dir2barcodes = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Barcodes_dataset\"\n",
    "\n",
    "with open(f\"{dir2publaynet}/train_syn.json\", 'r') as f:\n",
    "    publaynet = json.load(f)   \n",
    "\n",
    "with open(f\"{dir2stamps}/splits.json\", 'r') as f:\n",
    "    stamps = json.load(f)\n",
    "    \n",
    "with open(f\"{dir2signatures}ds3_splits.json\", 'r') as f:\n",
    "    signatures = json.load(f) \n",
    "\n",
    "with open(f\"{dir2qrs}/splits.json\", 'r') as f:\n",
    "    qrs = json.load(f)\n",
    "\n",
    "with open(f\"{dir2barcodes}/splits.json\", 'r') as f:\n",
    "    barcodes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "img = plt.imread(f\"{dir2publaynet}/{split}/{publaynet['images'][0]['file_name']}\")\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ds_dir = \"C:/Users/Maria/OneDrive - UAB/Documentos/3r de IA/Synthesis project II/Github/Project_Synthesis2-/Datasets/Synthetics_DS\"\n",
    "os.makedirs(ds_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\"categories\":publaynet[\"categories\"].copy(),\n",
    "            \"images\":publaynet[\"images\"].copy(),\n",
    "            \"annotations\":publaynet[\"annotations\"].copy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"categories\"].append({'supercategory': '', 'id': 6, 'name': 'signature'})\n",
    "dataset[\"categories\"].append({'supercategory': '', 'id': 7, 'name': 'stamp'})\n",
    "dataset[\"categories\"].append({'supercategory': '', 'id': 8, 'name': 'qr'})\n",
    "dataset[\"categories\"].append({'supercategory': '', 'id': 9, 'name': 'barcode'})\n",
    "dataset[\"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the publaynet 100 first images and place 3 signatures on each image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for i, sample in enumerate(publaynet[\"images\"][:10]):    \n",
    "    # plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    page = cv2.imread(f\"{dir2publaynet}/{split}/{sample['file_name']}\")\n",
    "    page = cv2.cvtColor(page, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    n = np.random.randint(1, 4)\n",
    "    img, dataset = add_stamps(n, page, stamps, dir2stamps, dataset, sample['id'])\n",
    "    \n",
    "    n = np.random.randint(1, 4)\n",
    "    img, dataset = add_signatures(n, img, signatures, dir2signatures, dataset, sample['id'])\n",
    "    \n",
    "    n = np.random.randint(1, 4)\n",
    "    img, dataset = add_qrs(n, img, qrs, dir2qrs, dataset, sample['id'])\n",
    "    \n",
    "    n = np.random.randint(1, 4)\n",
    "    img, dataset = add_barcodes(n, img, barcodes, dir2barcodes, dataset, sample['id'])\n",
    "    \n",
    "    # Save the image\n",
    "    os.makedirs(f\"{ds_dir}/{split}\", exist_ok=True)\n",
    "    cv2.imwrite(f\"{ds_dir}/{split}/{sample['file_name']}\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
